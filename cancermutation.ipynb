{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38a10c-5481-46be-b2d3-321fc682655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, max_error\n",
    "import shap\n",
    "\n",
    "# Assuming you have a CSV file as your dataset\n",
    "data = pd.read_csv('yourfile.csv')\n",
    "\n",
    "# Handle missing values (if any)\n",
    "data = data.dropna()\n",
    "\n",
    "# Encode categorical variables (assuming they are object types)\n",
    "data_encoded = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data_encoded.drop('Overall_Survival_Months', axis=1)  # Features\n",
    "y = data_encoded['Overall_Survival_Months']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter Tuning using RandomizedSearchCV\n",
    "\n",
    "# Random Forest\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [10, 20, 50, 100, 150, 200, 250, 300, 350, 500, 750, 1000],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20, 50, 100],\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 12, 15, 20]\n",
    "}\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "random_search_rf = RandomizedSearchCV(rf_model, param_distributions=param_dist_rf, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search_rf.fit(X_train_scaled, y_train)\n",
    "best_rf_model = random_search_rf.best_estimator_\n",
    "\n",
    "# Gradient Boosting\n",
    "param_dist_gb = {\n",
    "    'n_estimators': [10, 20, 50, 100, 150, 200, 250, 300, 350, 500, 750, 1000],\n",
    "    'max_depth': [3, 5, 7, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20, 50, 100],\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 12, 15, 20],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.5]\n",
    "}\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "random_search_gb = RandomizedSearchCV(gb_model, param_distributions=param_dist_gb, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search_gb.fit(X_train_scaled, y_train)\n",
    "best_gb_model = random_search_gb.best_estimator_\n",
    "\n",
    "# MLP Regression\n",
    "mlp_model = MLPRegressor(random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "#other models\n",
    "LR_model = LinearRegression()\n",
    "LR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "Lasso_model = Lasso()\n",
    "Lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "SVR_model = SVR()\n",
    "SVR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "KNR_model = KNeighborsRegressor()\n",
    "KNR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "DTR_model = DecisionTreeRegressor()\n",
    "DTR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Define models and model_names\n",
    "models = [best_rf_model, best_gb_model, mlp_model, LR_model, Lasso_model, SVR_model, KNR_model, DTR_model]\n",
    "model_names = ['Random Forest', 'Gradient Boosting', 'MLP', 'LinearRegression', 'Lasso', 'SVR', 'KNeighborsRegressor', 'DecisionTreeRegressor']\n",
    "\n",
    "# Model Evaluation with Cross-Validation\n",
    "for model, name in zip(models, model_names):\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    medae = median_absolute_error(y_test, predictions)\n",
    "    maxe = max_error(y_test, predictions)\n",
    "\n",
    "    print(f\"\\n{name} Metrics:\")\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "    print(\"Median Absolute Error:\", medae)\n",
    "    print(\"Max Error:\", maxe)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Print cross-validation results\n",
    "    print(f\"\\n{name} Cross-Validation Scores:\")\n",
    "    print(\"Mean MSE:\", -cv_scores.mean())\n",
    "    print(\"Std MSE:\", cv_scores.std())\n",
    "    \n",
    "    # Scatter Plot\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(y_test, predictions)\n",
    "    plt.title(f'{name} - Predicted vs Actual')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.xlim([0, max(y_test)+1])\n",
    "    plt.ylim([0, max(y_test)+1])\n",
    "    plt.gca().set_aspect('equal', adjustable='box')  # Set aspect ratio to be equal\n",
    "    plt.show()\n",
    "    \n",
    "# Example for using Shapley values with a model\n",
    "explainerrf = shap.Explainer(best_rf_model)\n",
    "shap_valuesrf = explainerrf.shap_values(X_test_scaled)\n",
    "shap.summary_plot(shap_valuesrf, X_test_scaled, feature_names=X.columns)\n",
    "\n",
    "explainergb = shap.Explainer(best_gb_model)\n",
    "shap_valuesgb = explainergb.shap_values(X_test_scaled)\n",
    "shap.summary_plot(shap_valuesgb, X_test_scaled, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b208b-97ea-4e01-9c2c-5e74ad26b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Best-performing models\n",
    "best_rf_model = random_search_rf.best_estimator_\n",
    "best_gb_model = random_search_gb.best_estimator_\n",
    "\n",
    "# Create ensemble using VotingRegressor\n",
    "ensemble_model = VotingRegressor([\n",
    "    ('RandomForest', best_rf_model),\n",
    "    ('GradientBoosting', best_gb_model)\n",
    "])\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "predictions_ensemble = ensemble_model.predict(X_test_scaled)\n",
    "\n",
    "mse_ensemble = mean_squared_error(y_test, predictions_ensemble)\n",
    "mae_ensemble = mean_absolute_error(y_test, predictions_ensemble)\n",
    "medae_ensemble = median_absolute_error(y_test, predictions_ensemble)\n",
    "maxe_ensemble = max_error(y_test, predictions_ensemble)\n",
    "\n",
    "print(\"\\nEnsemble Model Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_ensemble)\n",
    "print(\"Mean Absolute Error:\", mae_ensemble)\n",
    "print(\"Median Absolute Error:\", medae_ensemble)\n",
    "print(\"Max Error:\", maxe_ensemble)\n",
    "\n",
    "# Scatter Plot for Ensemble Model\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, predictions_ensemble)\n",
    "plt.title('Ensemble Model - Predicted vs Actual')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.xlim([0, max(y_test)+1])\n",
    "plt.ylim([0, max(y_test)+1])\n",
    "plt.gca().set_aspect('equal', adjustable='box')  # Set aspect ratio to be equal\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24221e18-3c5a-4ae2-a47a-b2f614a015eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning for Random Forest Regressor\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 15, 20, 25, 50, 75, 100, 150, 200, 250, 500, 750, 1000],\n",
    "    'max_depth': [None, 1, 2, 4, 6, 8, 10, 20, 50, 100],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10, 15, 20, 25, 50, 75, 100],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8, 10, 15, 20, 25, 50, 75, 100]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best model from the grid search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Feature Importance Analysis\n",
    "feature_importances = best_rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_results = cross_val_score(best_rf_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mse_scores = -cv_results\n",
    "print(\"Cross-Validation Mean Squared Error:\", cv_mse_scores.mean())\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate and print regression metrics\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "medae = median_absolute_error(y_test, predictions)\n",
    "maxe = max_error(y_test, predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test Mean Squared Error: {mse}\")\n",
    "print(f\"Test Mean Absolute Error: {mae}\")\n",
    "print(f\"Test Median Absolute Error: {medae}\")\n",
    "print(f\"Test Max Error: {maxe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09535022-ed06-4a3c-8ce7-7ea4418388fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning for Gradient Boosting Regressor\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 15, 20, 25, 50, 75, 100, 150, 200, 250, 500, 750, 1000],\n",
    "    'max_depth': [None, 1, 2, 4, 6, 8, 10, 20, 50, 100],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10, 15, 20, 25, 50, 75, 100],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8, 10, 15, 20, 25, 50, 75, 100]\n",
    "}\n",
    "\n",
    "gb_model = GradientBoostingRegressor()\n",
    "grid_search = GridSearchCV(gb_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best model from the grid search\n",
    "best_gb_model = grid_search.best_estimator_\n",
    "\n",
    "# Feature Importance Analysis\n",
    "feature_importances = best_gb_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_results = cross_val_score(best_gb_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mse_scores = -cv_results\n",
    "print(\"Cross-Validation Mean Squared Error:\", cv_mse_scores.mean())\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = best_gb_model.predict(X_test)\n",
    "\n",
    "# Calculate and print regression metrics\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "medae = median_absolute_error(y_test, predictions)\n",
    "maxe = max_error(y_test, predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test Mean Squared Error: {mse}\")\n",
    "print(f\"Test Mean Absolute Error: {mae}\")\n",
    "print(f\"Test Median Absolute Error: {medae}\")\n",
    "print(f\"Test Max Error: {maxe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54866c73-56ee-4cfb-8e33-a83e5a0a7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, max_error\n",
    "\n",
    "# Assuming you have already defined your models (best_rf_model, best_gb_model, mlp_model, etc.)\n",
    "\n",
    "# Define models and model_names\n",
    "models = [best_rf_model, best_gb_model]\n",
    "model_names = ['Random Forest', 'Gradient Boosting']\n",
    "\n",
    "# List to store predictions from each fold\n",
    "all_fold_predictions = []\n",
    "\n",
    "# Perform cross-validated predictions and store predictions in the list\n",
    "for model, name in zip(models, model_names):\n",
    "    predictions_fold = cross_val_predict(model, X_train_scaled, y_train, cv=5)\n",
    "    all_fold_predictions.append(predictions_fold)\n",
    "\n",
    "# Calculate the mean prediction across all folds\n",
    "mean_predictions = np.mean(all_fold_predictions, axis=0)\n",
    "\n",
    "# Evaluate the mean predictions\n",
    "mse_mean = mean_squared_error(y_train, mean_predictions)\n",
    "mae_mean = mean_absolute_error(y_train, mean_predictions)\n",
    "medae_mean = median_absolute_error(y_train, mean_predictions)\n",
    "maxe_mean = max_error(y_train, mean_predictions)  # Added this line\n",
    "\n",
    "print(\"\\nMean Ensemble Model Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_mean)\n",
    "print(\"Mean Absolute Error:\", mae_mean)\n",
    "print(\"Median Absolute Error:\", medae_mean)\n",
    "print(\"Max Error:\", maxe_mean)\n",
    "\n",
    "# Scatter Plot for Mean Ensemble Model with Actual Values below 40\n",
    "plt.scatter(y_train, mean_predictions)\n",
    "plt.title('Mean Ensemble Model - Predicted vs Actual')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0d4c5-fbb3-4c61-98ae-d051f0a7d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for using Shapley values with a model\n",
    "explainerrf = shap.Explainer(best_rf_model)\n",
    "shap_valuesrf = explainerrf.shap_values(X_test_scaled)\n",
    "shap.summary_plot(shap_valuesrf, X_test_scaled, feature_names=X.columns)\n",
    "\n",
    "explainergb = shap.Explainer(best_gb_model)\n",
    "shap_valuesgb = explainergb.shap_values(X_test_scaled)\n",
    "shap.summary_plot(shap_valuesgb, X_test_scaled, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49edf21-dd96-4ea4-afc0-fe3d2178af2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
